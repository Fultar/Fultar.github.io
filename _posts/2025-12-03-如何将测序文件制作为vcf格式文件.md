---
title: "如何将测序文件制作为vcf格式的文件"
date: 2025-12-03
categories: 
 - 生物信息学
 - 测序分析
 - 变异查找
tags: 
 - VCF
 - bwa
 - GATK
 - SNP calling
 - bash
---

# 一、序列比对

## 1.1 构建参考基因组的索引


我们将样品送到公司双端测序后，给的文件是`sample01.R1.gz sample01.R2.gz`这样一对的形式，一个是正链测序，另一个是负链测序结果。

首先，我们需要测序物种的参考基因组才能比对。参考基因组可以在ncbi上找到：https://www.ncbi.nlm.nih.gov/

下载好参考基因组后，我使用bwa软件建立参考基因组的索引：
```
# 这一步可能会花费些时间，我用nohup后台运行
nohup bwa index -a is GCA_022435785.1_ASM2243578v1_genomic.fna > bwa_index.log 2>&1 &

# 会生成5个索引文件：*.amb, *.ann, *.bwt, *.pac, *.sa
```

## 1.2 序列比对
看下bwa比对有哪些参数：
```
# 参数
bwa mem genomic.fa sample.R1.gz sample.R2.gz \
    -R '@RG\tID:sample\tLB:sample\tSM:sample\tPL:ILLUMINA' \ 2>sample_map.log \
    | samtools sort -@ 20 -O bam -o sample.sorted.bam 1>sample_sort.log 2>&1

# -R 选项为必须选项，用于定义头文件中的SAM/BAM文件中的read group和sample信息
```
SAM文件由两部分组成，头部区和主体区，都以tab分列:

- 头部区：以’@'开始，体现了比对的一些总体信息:
> @HD VN:1.0 SO:unsorted （排序类型）

> @SQ SN:contig1 LN:9401 （序列ID及长度）

> @RG ID:sample01 （样品基本信息）

> @PG ID:bowtie2 PN:bowtie2 VN:2.0.0-beta7 （比对所使用的软件及版本）

- 主体区：比对结果，每一个比对结果是一行，有11个主列和一个可选列:
> **QNAME** :比对的序列名称

> **FLAG** :Bwise FLAG（表明比对类型：paring，strand，mate strand等）

> **RENAME** :比对上的参考序列名;例如：NC_000075.6

> **POS**: 1-Based的比对上的最左边的定位

> **MAPQ**: 比对质量

> **CIGAR Extended CIGAR string**:（操作符：MIDNSHP）比对结果信息；匹配碱基数，可变剪接等

> **MRNM**: 相匹配的另外一条序列，比对上的参考序列名

> **MPOS**: 1-Based leftmost Mate Position （相比于MRNM列来讲意思和POS差不多

> **ISIZE**: 插入片段长度

> **SEQ**: 和参考序列在同一个链上比对的序列（若比对结果在负义链上，则序列是其反向重复序列，反向互补序列

> **QUAL**: 比对序列的质量（ASCII-33=Phred base quality）reads碱基质量值

**序列比对脚本：**
运行该bash脚本，会在路径下生成```sam.sh```文件，里面的命令行就是所有需要比对的样本，可以每次执行五六个，避免服务器的计算资源耗尽
```
#!/bin/bash

for file in `ls -d ../rawdata/MS24_DNA_431-702/*R1.*.gz`; do
    out_file=${file%.R*}
    out_file=${out_file#../rawdata/MS24_DNA_431-702/}
    
    export a
    export b
    
    for file in `ls ../rawdata/MS24_DNA_431-702/${out_file}.R1*`; do
        a=${file}
    done
    
    for file in `ls ../rawdata/MS24_DNA_431-702/${out_file}.R2*`; do
        b=${file}
    done
    
    echo "nohup bwa mem -t 4 -M -R \"@RG\tID:$out_file\tPU:$out_file\tSM:$out_file\tPL:ILLUMINA\tLB:$out_file\" ../genome/GCA_022435785.1_index/GCA_022435785.1_ASM2243578v1_genomic.fna $a $b -o ${out_file}.sam >${out_file}.sam.log"
done > sam.sh
```

打印bwa命令行的a和b参数，并检查样本是否相同，是否分别为R1和R2文件：
```
awk '{print "ls -l  "$10}' sam.sh >z
wc -l z
sh z

awk '{print "ls -l  "$11}' sam.sh >z
wc -l z
sh z
rm z
```

优化bash脚本内容：
```
awk '{if(num==19){num=0;print} else{num++;print $0"\t&"}}' sam.sh >t

mv t sam.sh

echo >> sam.sh

echo "wait" >> sam.sh

echo "echo \"sam.sh for 6 is done\"" >>sam.sh

cat sam.sh
```

如果上述命令一切正常，我们就可以运行脚本，开始生成sam比对结果文件：
```
sh sam.sh >sam.sh.log &

mkdir sam_log
mv *.sam.log sam_log/
cd sam_log

# 查看日志有无报错
for file in `ls *.sam.log`; do echo "$file"; tail -1 $file; done >sam_check 

```


## 1.3 验证sam文件
这里开始，我们使用`gatk`软件进行后续步骤。

`gatk ValidateSamFile`命令可以验证sam文件是否是标准格式。
```
# 验证sam文件的格式有无错误，不然后续步骤会报错
for file in `ls *.sam`; do x=${file/.sam/}; echo "nohup gatk  ValidateSamFile --INPUT "$file" >"$x".validate.log &"; done >validate.sh

sh validate.sh >validate.sh.log &

```

为避免程序太多挤占服务器资源，可以修改上述脚本，分批运行程序：
```
#!/bin/bash

count=0
for sam in MS24_P2_*.sam; do
  name=${sam%.sam}
  nohup gatk ValidateSamFile --INPUT "$sam" > "${name}.validate.log" &
  
  count=$((count + 1))
  
  if [[ $((count % 6)) -eq 0 ]]; then
    wait  # 等待当前这6个任务结束
  fi
done

wait  # 等待最后一组不足6个的任务
```

查看验证结果：
```
mkdir validate_log
mv *.validate.log validate_log/
cd validate_log/

# 运行check脚本
for file in `ls *.validate.log`; do echo "$file"; tail -1 $file; done >validate_check ##normal
# cat检查内容有无error；如果正确则返回“0”。

cd ..

```

## 1.4 SAM文件排序并压缩为BAM格式文件

使用`gatk SortSam`命令压缩sam文件
```
gatk SortSam -I samplename.sam \
-O samplename_sorted.bam \
--TMP_DIR sample.tmp \
-SO coordinate

-I 你的sam文件路径
-O 指定bam文件名
--TMP_DIR 临时文件路径
-SO coordinate 排序sam文件
```

我这里同时运行4个任务，防止任务太多挤占服务器资源
```
#!/bin/bash

count=0
for sam in MS24_P2_*.sam; do
  name=${sam%.sam}
  nohup gatk SortSam -I "$sam" -O "$name"_sorted.bam --TMP_DIR "$name".tmp -SO coordinate >"$name"_sorted.bam.log 2>"$name"_sorted.bam.log.2 &
  
  count=$((count + 1))
  
  if [[ $((count % 4)) -eq 0 ]]; then
    wait  # 等待当前这4个任务结束
  fi
done
wait  # 等待最后一组不足4个的任务
echo "sort_sam.sh done\n"

```


```
# 运行脚本
sh sort_sam.sh >>sort_sam.sh.log 2>>sort_sam.sh.log &

mkdir sort_bam_log

mv *_sorted.bam.log sort_bam_log/
mv *_sorted.bam.log.2 sort_bam_log/

cd sort_bam_log

# 检查排序后的bam文件有无报错：
for file in `ls *.bam.log`; do more $file; done >check

## 如果无报错则输出：
## Tool returned:
## 0


cd ..

# 查看bam文件是否排序（表头带SO:coordinate）
samtools view -H my.bam

```

## 1.5 标记重复片段
在文库制备过程中，PCR扩增会产生相同DNA片段的多个拷贝，但其实这些拷贝来自同一个原始DNA分子，不代表真实的生物学信号。

如果不去重会夸大测序深度，因为10个重复reads实际只代表1个原始DNA分子，导致覆盖度评估不准确。同时由于PCR错误会在所有拷贝中重复出现，使假阳性突变位点增加、等位基因频率计算错误、定量分析失真，对后续的分析都会造成影响。

这只针对DNA测序，RNA-Seq一般不去重。

使用gatk的```MarkDuplicates```参数去重：
```
-M samplename.deduplicated.metrics

# 指定标记到的重复序列的文件名
```


```
#!/bin/bash

count=0
for bam in *_sorted.bam; do
  name=${bam%_sorted.bam}
  nohup gatk MarkDuplicates -I "$bam" -O "$name".deduplicated -M "$name".deduplicated.metrics  >"$name".deduplicated.log 2>"$name".deduplicated.log.2 &
  
  count=$((count + 1))
  
  if [[ $((count % 4)) -eq 0 ]]; then
    wait  # 等待当前这4个任务结束
  fi
done
wait  # 等待最后一组不足4个的任务
echo "sort_sam.sh done\n"

```


```
# 运行脚本
sh markDuplicates.sh >markDuplicates.sh.log  &

ll -h *.deduplicated

mkdir deduplicated_log

mv *.deduplicated.log* deduplicated_log/
mv *.deduplicated.metrics deduplicated_log/
cd deduplicated_log/

for file in `ls *.deduplicated.log`; do echo $file; more $file; done >check

## 若无报错，则返回：
## Tool returned:
## 0

```


# 二、SNP caling
## 2.1 为bam文件构建索引
同样，我们需要先对处理好的bam文件构建索引：
```
#!/bin/bash

count=0
for file in *.deduplicated; 
do
  nohup samtools index "$file" > "$file".index.log&
  
  count=$((count + 1))
  
  if [[ $((count % 4)) -eq 0 ]]; then
    wait  # 等待当前这4个任务结束
  fi
done
wait  # 等待最后一组不足4个的任务
echo "index.sh done\n"

```

运行脚本：
```
sh index_deduplicated.sh >index_deduplicated.sh.log &

ls *.bai|wc -l

# 构建基因组文件索引
gatk CreateSequenceDictionary -R genome.fasta 

```
## 2.2 SNP calling 变异查找
准备好bam文件（`*.deduplicated`后缀表示是去重复片段的bam文件）、参考基因组后，我们要先对单个样本生成`.gvcf`后缀的文件，然后再把单个样本的`gvcf`合并为群体的`vcf`格式。

使用参数`--pcr-indel-model CONSERVATIVE -ERC GVCF`生成单样本`gvcf`格式文件：
```
#!/bin/bash

count=0
for file in *.deduplicated; do
  name=${file%.deduplicated}
  nohup gatk HaplotypeCaller --pcr-indel-model CONSERVATIVE -ERC GVCF -R /home/genome/GCA_022435785.1_index/GCA_022435785.1_ASM2243578v1_genomic.fna -I "$file" -O "$name".gvcf >"$name".gvcf.log 2>"$name".gvcf.log.2 &
  
  count=$((count + 1))
  
  if [[ $((count % 4)) -eq 0 ]]; then
    wait  # 等待当前这4个任务结束
  fi
done
wait  # 等待最后一组不足4个的任务
echo "gvcf.sh done\n"
```

运行脚本：
```
sh vcf.sh >gvcf.sh.log 2>&1 &

ll -h *.gvcf

mkdir gvcf_log
mv *.gvcf.idx gvcf_log/
mv *.gvcf.log  gvcf_log/
mv *.gvcf.log.2 gvcf_log/
cd gvcf_log/

# 检查有无报错
for file in `ls *.gvcf.log.2`; do tail -2 $file; done >check 
cd ..

for file in `ls *.gvcf`; do x=${file/gvcf/}gvcf; mv $file $x; done

## gvcf文件的ALT列若为“<NON_REF>”，说明该位点未观察到突变型碱基，大概率为纯和参考型碱基，即0/0；
## 具体的概率可参考GQ列的信息：GQ = -10 × log10(P(错误的基因型))；
## 如果 GQ = 20，表示我们认为当前基因型是错的概率约为 1/100 = 10^(-20/10)

```

## 2.3 （不推荐）一步法合并gvcf文件

这种方法耗时长，而且如果程序被中断，只能从头再来，不推荐。

1. 把每个样本的gvcf合并：

```
ls *.gvcf >t

awk '{c=c" -V "$0}END{print "nohup gatk CombineGVCFs  -R /home/genome/GCA_022435785.1_index/GCA_022435785.1_ASM2243578v1_genomic.fna "c" -O MS24_P2_combined.gvcf &"}' t >tt

sh tt 

```

2. 合并完成后检测基因分型，得到完整的vcf文件：

```
nohup gatk GenotypeGVCFs -R /home/genome/GCA_022435785.1_index/GCA_022435785.1_ASM2243578v1_genomic.fna -V MS24_P2_combined.gvcf -O MS24_P2_combined.final.vcf >vcf_combined.final.log 2>vcf_combined.final.error&

```
## 2.4 **（推荐）GVCF文件按染色体合并、检测基因分型：**

这种方法先按染色体的顺序合并不同样本的gvcf，再对染色体的合并文件call snp，最后合并所有染色体的vcf文件。此法可并行，运行速度快，而且被中断只是单个染色体被中断，影响小，推荐。

### 2.4.1. 整理需要合并的gvcf文件名

- 制作sample_map文件，包含需要合并的样本：

```
#!/bin/bash

# 输出文件名
output="sample_table.txt"

# 初始化计数器
i=1

# 清空旧输出
> "$output"

# 遍历所有 .gvcf 文件
for file in MS24_P2_*.gvcf; do
    sample_id="sample${i}"
    echo -e "${sample_id}\t${file}" >> "$output"
    ((i++))
done
```

- 输出文件格式，第一列为新样本名，第二列为待合并的gvcf样本名，两个名字可以一样，也可以不一样重新命名：

```
$head sample_table.txt
sample1      sample1.gvcf.gz
sample2      sample2.gvcf.gz
sample3      sample3.gvcf.gz
```


### 2.4.2 按染色体分割gvcf
这步将每个样本`gvcf`的染色体数据摘取出来。
 - GenomicsDBImport生成数据集

```
#!/bin/bash

>tt

for i in $(seq 32 54); 
do
# 染色体名
  CHR="CM0395${i}.1"

echo "nohup gatk GenomicsDBImport  \
    --genomicsdb-workspace-path ./vcf_chr/bass_${CHR} \
    -R /home/genome/GCA_022435785.1_index/GCA_022435785.1_ASM2243578v1_genomic.fna \  
    --sample-name-map sample_table.txt \
    -L ${CHR} \
    >${CHR}_nohup.log 2>${CHR}_error.log &" >>tt
done
```
```
sh tt >chr.log&
```

- 运行完成后会在路径下生成一系列以染色体`./vcf_chr/bass_${CHR}`命名的路径和文件

- 检查合并有无出错：

```
for file in `ls *_nohup.log`; do more $file; done >check

cat check

## 如果正常运行结束，无报错，则输出：
Tool returned:
true

```

### 2.4.3 对染色体数据集查找变异

上一步对样本的染色体生成一系列以染色体名`./vcf_chr/bass_${CHR}`分类的路径和零散文件，这步需要对每条染色体检测变异位点：

```
nohup gatk GenotypeGVCFs \
    -R /home/genome/GCA_022435785.1_index/GCA_022435785.1_ASM2243578v1_genomic.fna \
    -V gendb://bass_CM039554.1 \
    -O ./bass_CM039554.1/MS24_P2_CM039554.1.vcf.gz \
    >called_CM039554.1.nohup.log 2>called_CM039554.1.error.log&

```

- 脚本：

```
#!/bin/bash

>tt

index="/home/genome/GCA_022435785.1_index/GCA_022435785.1_ASM2243578v1_genomic.fna"

for i in $(seq 32 53); 
do
  CHR="CM0395${i}.1"

echo "nohup gatk GenotypeGVCFs -R ${index} -V gendb://bass_${CHR} -O ./bass_${CHR}/MS24_P2_${CHR}.vcf.gz >called_${CHR}.nohup.log 2>called_${CHR}.error.log&" >> tt

done

wait 
echo "Mission Complete."
```

检查有无报错：

```
for file in `ls *.error.log`; do tail -4 $file; done >check
```

## 2.4.4. 合并vcf样本
对每条染色体查找变异后，我们便可以把结果合并起来，组成样本群体的vcf文件。

```
#!/bin/bash

# 输出合并后的文件名
output="MS24_P2_merged.vcf.gz"

# 初始化输入参数
input_params=""

# 遍历每个 bass_CM* 子目录
for dir in bass_CM*; do
    # 查找该目录下的 .vcf.gz 文件
    vcf_file=$(find "$dir" -name "*.vcf.gz" | head -n 1)

    # 如果找到文件，则追加到参数
    if [[ -f "$vcf_file" ]]; then
        input_params+=" I=$vcf_file"
    fi
done

# 检查是否找到了至少两个文件
if [[ $(echo "$input_params" | wc -w) -lt 2 ]]; then
    echo "Error: 找到的VCF文件少于两个，无法合并。"
    exit 1
fi

# 执行 GATK MergeVcfs
echo "正在合并以下VCF文件："
echo "$input_params"

echo "nohup gatk MergeVcfs $input_params O=$output >combined_chr_vcf.nohup.log 2>combined_chr_vcf.error.log&" >t

```

```
# 运行脚本
sh t >combined_vcf.log $
```

运行完成生成`vcf`格式文件，可用于gwas后续分析了。